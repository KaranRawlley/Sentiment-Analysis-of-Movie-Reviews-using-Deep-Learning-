{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from numpy import array \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, RepeatVector, Flatten\n",
    "from keras.layers import LSTM, Bidirectional, Dropout, Permute, Multiply, Lambda\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Well, you'd better if you plan on sitting thro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Moonwalker is a Fantasy Music film staring Mic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I bought this video on a throw-out table at th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Since the last horrid Astérix film and the fac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I grew up with the Abbott and Costello movies,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  Well, you'd better if you plan on sitting thro...          0\n",
       "1  Moonwalker is a Fantasy Music film staring Mic...          1\n",
       "2  I bought this video on a throw-out table at th...          0\n",
       "3  Since the last horrid Astérix film and the fac...          1\n",
       "4  I grew up with the Abbott and Costello movies,...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reviews.csv')\n",
    "df.isnull().values.any() # checks if data file have any null values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  text = re.sub('<[^>]*>', '', text)\n",
    "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "  text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "      ' '.join(emoticons).replace('-', '')\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(df['reviews'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess(sen))\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "print(len(X_train[1]))\n",
    "print(len(X_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GloVe for creating feature matrix\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('glove.6B.300d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94562"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(inputs):\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(1, activation='softmax')(a)\n",
    "    a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "    a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = Multiply()([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rawll\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rawll\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "units=200\n",
    "vocab_size = embedding_matrix.shape[0]\n",
    "embedding_size = embedding_matrix.shape[1]\n",
    "_input = Input(shape=(maxlen, ))\n",
    "\n",
    "# get the embedding layer\n",
    "embedded = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_size,\n",
    "        input_length=maxlen,\n",
    "        trainable=False,\n",
    "        mask_zero=False,\n",
    "        weights=[embedding_matrix]\n",
    "    )(_input)\n",
    "\n",
    "#bi-directional lstm layer\n",
    "bidi_lstm_out = Bidirectional(LSTM(units, return_sequences=True, dropout=0.25,\n",
    "                           recurrent_dropout=0.25))(embedded)\n",
    "\n",
    "#adding attention\n",
    "attention_mul = attention(bidi_lstm_out)\n",
    "attention_mul = Flatten()(attention_mul)\n",
    "output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "model = Model(input=[_input], output=output)\n",
    "\n",
    "#compiling model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 300)     28368600    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 400)     801600      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 400, 100)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 400, 1)       101         permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dim_reduction (Lambda)          (None, 1)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 400, 1)       0           dim_reduction[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 1, 400)       0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100, 400)     0           bidirectional_1[0][0]            \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 40000)        0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            40001       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,210,302\n",
      "Trainable params: 841,702\n",
      "Non-trainable params: 28,368,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rawll\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 189s 5ms/step - loss: 0.4288 - accuracy: 0.7983 - val_loss: 0.3539 - val_accuracy: 0.8390\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 192s 5ms/step - loss: 0.3252 - accuracy: 0.8582 - val_loss: 0.3308 - val_accuracy: 0.8566\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 193s 5ms/step - loss: 0.2603 - accuracy: 0.8894 - val_loss: 0.3403 - val_accuracy: 0.8549\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 196s 5ms/step - loss: 0.1809 - accuracy: 0.9283 - val_loss: 0.3970 - val_accuracy: 0.8453\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 196s 5ms/step - loss: 0.1138 - accuracy: 0.9582 - val_loss: 0.4454 - val_accuracy: 0.8383\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 201s 5ms/step - loss: 0.0723 - accuracy: 0.9741 - val_loss: 0.5245 - val_accuracy: 0.8408\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 199s 5ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.5682 - val_accuracy: 0.8409\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 200s 5ms/step - loss: 0.0390 - accuracy: 0.9862 - val_loss: 0.6270 - val_accuracy: 0.8433\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 203s 5ms/step - loss: 0.0362 - accuracy: 0.9871 - val_loss: 0.6713 - val_accuracy: 0.8397\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 200s 5ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.7134 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b9c29e7550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tensorflow]",
   "language": "python",
   "name": "conda-env-.conda-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
